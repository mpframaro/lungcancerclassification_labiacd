{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7ca8f-7794-4f85-aa8e-ffc2186a0b40",
   "metadata": {},
   "source": [
    "# Test diffrent models for NN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2cf7a-7a39-459d-93f2-e5b50035cf5c",
   "metadata": {},
   "source": [
    "In this notebook we will test the machine learning frameworks TensorFlow, PyTorch, and Scikit-Learnâ€”on our datasets. The models will iterates over six different datasets: non normalized, normalized, and data grouped by slices, annotations, nodules. To observe the impact of data normalization and dataset structure on model performance and also which model we should proceed with.\n",
    "\n",
    "The notebook implements three neural network models:\n",
    "\n",
    "TensorFlow Model: A sequential neural network with two hidden layers of 60 neurons each, using ReLU activations and trained with categorical cross-entropy loss.\n",
    "<br>\n",
    "<br>\n",
    "PyTorch Model: A custom neural network with two fully connected layers, using ReLU activation functions and trained using cross-entropy loss.\n",
    "<br>\n",
    "<br>\n",
    "Scikit-Learn MLP Model: A multi-layer perceptron classifier with two hidden layers of 60 neurons, utilizing ReLU activations, trained through the Scikit-Learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1674a8ed-8db6-41c7-9449-47223ed04f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f81db463-42b1-40f2-9091-2d74224954a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of datasets\n",
    "datasets = [\n",
    "    \"final_by_slices.csv\",\n",
    "    \"final_by_slices_normalized.csv\",\n",
    "    \"final_by_annotations.csv\",\n",
    "    \"final_by_annotations_normalized.csv\",\n",
    "    \"final_by_nodules.csv\",\n",
    "    \"final_by_nodules_normalized.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6415501a-fe5e-4f10-8336-182282c7974e",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b85ed39-fe28-496e-9030-8b425a16a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load and preprocess the dataset\n",
    "def preprocess_dataset(filename, label_column=\"malignancy\"):\n",
    "    # load the dataset\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # separate features and labels\n",
    "    X = df.drop(label_column, axis=1)\n",
    "    y = df[label_column]\n",
    "    \n",
    "    # one-hot encode the labels for TensorFlow and PyTorch \n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_onehot = encoder.fit_transform(y.values.reshape(-1, 1))\n",
    "    \n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5adc8-aab5-42d9-ba3f-8a547bd65ac8",
   "metadata": {},
   "source": [
    "## PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5b84ff0-9c49-475a-9509-7e76c49207fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create and train PyTorch model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 60)\n",
    "        self.fc2 = nn.Linear(60, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_pytorch(X_train, y_train, X_test, y_test):\n",
    "    model = SimpleNN(X_train.shape[1], y_train.shape[1])\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    # convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)\n",
    "\n",
    "    # train the model\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # evaluate the model\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long)\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = accuracy_score(y_test_tensor, predicted)\n",
    "        print(f'PyTorch Model Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81a5ff-4136-41ea-acf0-af35b06e295d",
   "metadata": {},
   "source": [
    "## TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c6ac488-e308-42c1-9ccf-dfc0841286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create and train TensorFlow model\n",
    "def train_tensorflow(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential([\n",
    "        Dense(60, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(60, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'TensorFlow Model Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f6992-c12c-401a-a9c4-849ebd473a17",
   "metadata": {},
   "source": [
    "## Scikit_Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21ec54e3-026c-4c5d-8fc3-1a5bcd8f2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create and train Scikit-Learn MLP model\n",
    "def train_sklearn(X_train, y_train, X_test, y_test):\n",
    "    model = MLPClassifier(\n",
    "    hidden_layer_sizes=(60),\n",
    "    activation='relu',\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    ")\n",
    "    model.fit(X_train, np.argmax(y_train, axis=1))\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    print(f'Scikit-Learn Model Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514a521-7601-4fe4-844e-fed178a06586",
   "metadata": {},
   "source": [
    "## Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ec466df-d049-4f19-9f53-0840a317b84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: final_by_slices.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TensorFlow model...\n",
      "TensorFlow Model Accuracy: 0.5005\n",
      "Training PyTorch model...\n",
      "PyTorch Model Accuracy: 0.5362\n",
      "Training Scikit-Learn model...\n",
      "Scikit-Learn Model Accuracy: 0.7481\n",
      "Finished processing dataset: final_by_slices.csv\n",
      "\n",
      "Processing dataset: final_by_slices_normalized.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TensorFlow model...\n",
      "TensorFlow Model Accuracy: 0.9186\n",
      "Training PyTorch model...\n",
      "PyTorch Model Accuracy: 0.8340\n",
      "Training Scikit-Learn model...\n",
      "Scikit-Learn Model Accuracy: 0.8795\n",
      "Finished processing dataset: final_by_slices_normalized.csv\n",
      "\n",
      "Processing dataset: final_by_annotations.csv\n",
      "Training TensorFlow model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Model Accuracy: 0.7184\n",
      "Training PyTorch model...\n",
      "PyTorch Model Accuracy: 0.5831\n",
      "Training Scikit-Learn model...\n",
      "Scikit-Learn Model Accuracy: 0.6704\n",
      "Finished processing dataset: final_by_annotations.csv\n",
      "\n",
      "Processing dataset: final_by_annotations_normalized.csv\n",
      "Training TensorFlow model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Model Accuracy: 0.8630\n",
      "Training PyTorch model...\n",
      "PyTorch Model Accuracy: 0.8431\n",
      "Training Scikit-Learn model...\n",
      "Scikit-Learn Model Accuracy: 0.8571\n",
      "Finished processing dataset: final_by_annotations_normalized.csv\n",
      "\n",
      "Processing dataset: final_by_nodules.csv\n",
      "Training TensorFlow model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Model Accuracy: 0.4869\n",
      "Training PyTorch model...\n",
      "PyTorch Model Accuracy: 0.6176\n",
      "Training Scikit-Learn model...\n",
      "Scikit-Learn Model Accuracy: 0.7255\n",
      "Finished processing dataset: final_by_nodules.csv\n",
      "\n",
      "Processing dataset: final_by_nodules_normalized.csv\n",
      "Training TensorFlow model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Model Accuracy: 0.8840\n",
      "Training PyTorch model...\n",
      "PyTorch Model Accuracy: 0.8529\n",
      "Training Scikit-Learn model...\n",
      "Scikit-Learn Model Accuracy: 0.8922\n",
      "Finished processing dataset: final_by_nodules_normalized.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through each dataset and train/evaluate the models\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing dataset: {dataset}\")\n",
    "    X_train, X_test, y_train, y_test = preprocess_dataset(dataset)\n",
    "    \n",
    "    print(\"Training TensorFlow model...\")\n",
    "    train_tensorflow(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"Training PyTorch model...\")\n",
    "    train_pytorch(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"Training Scikit-Learn model...\")\n",
    "    train_sklearn(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(f\"Finished processing dataset: {dataset}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f419e64-02ff-49e0-88c2-2bf826fb3a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
